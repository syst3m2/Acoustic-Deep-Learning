"""
 Andrew Pfau
 Spectrogram generator program
 this script generates spectrogram images from input audio files using matplotlib, tensorflow, librosa, or all 3
 the goal is to demonstrate various methods of generation and show that they produce the same output

  generate_from_model : This function is called from the tran_model.py program as part of the input pipeline if
  the '--print_specgram' flag is set on input. It will generate spectrograms and match them with their input label.
  This is useful for verifying that label and data matching is correct and for visualizing the data
  The number of spectrograms made is controlled by the PLOTS_TO_MAKE variable, default is 20 and should not be large. Cannot be larges than batch size
   All spectrograms are saved in the same file call 'test_spectro_tf.png'

  from_folder: This function will generate spectrograms from .wav files in a folder. Useful for generating spectrograms of
  many, or a few specific files.

"""

import librosa, librosa.display
import numpy as np
import matplotlib.pyplot as plt
import os
import argparse
import tensorflow as tf
import glob
import concurrent.futures

def generate_from_model(params, spec_batch, label_batch, time_axis, freq_axis):
   """
   This function is called from the main script to print out spectrograms and their labels if necessary
   Allows visualiztion of input to the model to verify that the data pipeline is functioning properly
   Args:
      params: command line input arguments
      spec_batch: tensor bacth of spectrograms generated by dataset_processor
      label_batch tensor batch of one hot encoding of labels associated with the spectrograms
      time_axis: number of smaple points in time axis
   """
   PLOTS_TO_MAKE = 20

   if params.channels==4:
       spec_batch = spec_batch[:,:,:,0]
       spec_batch = tf.expand_dims(spec_batch, axis=3)

   #print(spec_batch)
   #print(spec_batch.shape)
   class_names=np.array(params.classes.split(','))
   print(str(class_names))
   
   # plot setup
   plt.figure(figsize=(10,10))
   plt.tight_layout(pad=5.0)   # more space between plots in image
   print('Single sample shape: ' + str(tf.shape(spec_batch[0])))
   frequency_vector = np.linspace(0, params.sample_rate, num=freq_axis)
   frame_vector_time = np.linspace(0, params.duration ,num=time_axis )
   
   cmap = plt.cm.get_cmap("jet")
   # convert to a numpy array so that name labels can be given vice 1s and 0s
   temp_l = label_batch.numpy()

   for n in range(PLOTS_TO_MAKE):
      ax = plt.subplot(5,5,n+1)
      plt.axis('off')  # turn off axes
      spec_plot = np.transpose(np.squeeze(spec_batch[n].numpy(), 2))
      plt.pcolormesh(frame_vector_time, frequency_vector,spec_plot,cmap=cmap)
      title = class_names[temp_l[n]==1][0].title()
      plt.title(title)

   # save the image
   save_name = os.path.join(params.checkpoint_dir + 'test_spectro_tf.png')
   plt.savefig(save_name)
   plt.close()

def from_folder(switch_arg, tgt_dir, n_fft, overlap, rate, hop_length, win_size, dur):
   """
   The main function is called when the script is called from the command line
   This funciton will generate a spectrogram of the input audio file via one of several libraries
   this allows the user to compare how different library spectrograms look
   """

   for filename in glob.glob(tgt_dir + '/*.wav'):
      plt.clf()
      print('tgt file: ' + str(filename))
      fName = os.path.splitext(filename)[0]
      fig, ax = plt.subplots(1, figsize=(10,10))
      if('matplot' in switch_arg):
         signal, sr = librosa.load(os.path.join(tgt_dir, filename), sr=rate)

         # using matplotlib
         Pxx, freqs, bins, im = ax.specgram(signal, NFFT=n_fft, Fs = sr, noverlap=overlap)
         #plt.axis(ymax=300)

         plt.xlabel("Time")
         plt.ylabel("Frequency")
         plt.title(filename + ' Spectrogram')
         #plt.colorbar(format='%+2.0f dB')
         save_name = os.path.join(tgt_dir, fName + ' spectro_matplotlib.png')
         plt.savefig(save_name)
         plt.close()

      if('tf' in switch_arg):
         # using tensorflow
         raw_audio = tf.io.read_file(filename)
         audio, sr = tf.audio.decode_wav(raw_audio, desired_channels=1, desired_samples=-1)

         audio_for_stft = tf.reshape(tf.squeeze(audio), [1,-1])

         # shape is 
         # <tf.Tensor: shape=(1, 16000), dtype=float32, numpy=
         time_win = (int)((win_size * 0.001) *rate )
         spectrograms = tf.signal.stft(audio_for_stft, frame_length = time_win, frame_step = overlap, fft_length = n_fft, pad_end = True)
         # shape=(1, 32, 513)   as expected [batch, time, freqbins]
         freq_limit=100
         mag_spec = tf.math.abs(spectrograms, name="mag_specs")
         time_space = (int)(dur * rate) // overlap
         spec = (tf.math.log(mag_spec) / tf.math.log(tf.constant(10, dtype = mag_spec.dtype)))

         spec_plot = np.transpose(np.squeeze(spec.numpy(), 0))

         frequency_vector = np.linspace(0, rate, num=(n_fft//2)+1)
         frame_vector_time = np.linspace(0, dur, num=time_space )
         
         cmap = plt.cm.get_cmap("jet")
         plt.pcolormesh(frame_vector_time, frequency_vector,spec_plot,cmap=cmap)
         
         plt.title('STFT with Tensorflow')
         plt.ylabel('Frequency [Hz]')
         plt.xlabel('Time [sec]')
         plt.rcParams["figure.figsize"] = [40,10]
         save_name = os.path.join(tgt_dir, fName + ' spectro_tf.png')
         plt.savefig(save_name)
         plt.close()

      if('librosa' in switch_arg):
         # using librosa
         signal, sr = librosa.load(os.path.join(tgt_dir, filename), sr=rate)
         stft = librosa.core.stft(signal, hop_length=hop_length , n_fft= n_fft)
         spectrogram = np.abs(stft)
         log_spectrogram = librosa.amplitude_to_db(spectrogram)
         librosa.display.specshow(log_spectrogram, sr=sr, hop_length=hop_length)
         plt.colorbar(format='%+2.0f dB')
         plt.title('STFT with Librosa')
         plt.ylabel('Frequency [Hz]')
         plt.xlabel('Time [sec]')
         save_name = os.path.join(tgt_dir, fName + ' spectro_librosa.png')
         plt.savefig(save_name)
         plt.close()

def main():
   """
      Process command line arguments and call from_folder function.
   """
   parser = argparse.ArgumentParser()
   parser.add_argument('--data_dir',  type=str,  help="Directory of audio files.")
   parser.add_argument('--generator', type=str,  help="Which specgram generator to use. Matplot, tf, or librosa")

   # spectrogram parameters
   parser.add_argument('--win_size',    type=int, default=250,  help='Window size in mSec')
   parser.add_argument('--n_fft',       type=int, default=1024, help='Number of FFT sample points')
   parser.add_argument('--overlap',     type=int, default=50,   help='Spectrogram window overlap in percent')
   parser.add_argument('--sample_rate', type=int, default=4000, help='Sample rate of input audio')
   parser.add_argument('--hop_len',     type=int, default=2000, help='hop_length')
   parser.add_argument('--duration',    type=int, default=30,   help="Lenght of audio files in seconds. Default is 30")
   args =parser.parse_args()

   calc_overlap = (int) (args.overlap/100 *(args.win_size * 0.001 * args.sample_rate))
   #print(calc_overlap)

   from_folder(args.generator, args.data_dir, args.n_fft, calc_overlap, args.sample_rate, args.hop_len, args.win_size, args.duration)


if __name__ == "__main__":
   main()