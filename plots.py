from logging import error
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import main_pipeline
from vs_data_query import WavCrawler
#from data_pipeline.resources.ais_pipeline import *
from data_pipeline.resources.acoustic_pipeline import *
from scipy.signal import fir_filter_design, spectrogram
import data.dataset_processor as data_processor
#from utilities.data_vis_tools.spectrogram_generator import generate_from_model
import librosa, librosa.display
import numpy as np
import matplotlib.pyplot as plt
import os
import argparse
import tensorflow as tf
import glob
import concurrent.futures
import re
from dataReader import *
from utilities.time_ops import *
import re
from matplotlib.colors import ListedColormap
import matplotlib.patches as mpatches
from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt

def generate_from_model(params, spec_batch, label_batch, start_times, end_times, time_axis, freq_axis, batch_size=20):
    """
    This function is called from the main script to print out spectrograms and their labels if necessary
    Allows visualiztion of input to the model to verify that the data pipeline is functioning properly
    Args:
        params: command line input arguments
        spec_batch: tensor bacth of spectrograms generated by dataset_processor
        label_batch tensor batch of one hot encoding of labels associated with the spectrograms
        time_axis: number of smaple points in time axis
    """
    # Edit the number of plots to make to be dependent on the input
    PLOTS_TO_MAKE = 20

    if params.channels==4:
        spec_batch = spec_batch[:,:,:,0]
        spec_batch = tf.expand_dims(spec_batch, axis=3)

    #print(spec_batch)
    #print(spec_batch.shape)
    class_names=np.array(params.classes.split(','))

    # plot setup
    plt.figure(figsize=(10,10))
    plt.tight_layout(pad=5.0)   # more space between plots in image
    #plt.tight_layout(pad=5.0,h_pad=10,w_pad=20) 
    #print('Single sample shape: ' + str(tf.shape(spec_batch[0])))
    frequency_vector = np.linspace(0, params.sample_rate, num=freq_axis)
    frame_vector_time = np.linspace(0, params.duration ,num=time_axis )

    cmap = plt.cm.get_cmap("jet")
    # convert to a numpy array so that name labels can be given vice 1s and 0s
    temp_l = label_batch.numpy()

    for n in range(batch_size):
        if len(start_times)>0 and len(end_times)>0:
            start_time=utc_to_date(int(start_times[n]))
            end_time=utc_to_date(int(end_times[n]))
            time_range = start_time.strftime("%m/%d/%Y, %H:%M:%S") + ' - ' + end_time.strftime("%m/%d/%Y, %H:%M:%S")
        else:
            time_range = ''

        title = class_names[temp_l[n]==1][0].title()
        ax = plt.subplot(5,5,n+1)
        #ax = plt.subplot(batch_size,3,n+1)
        plt.axis('off')  # turn off axes
        spec_plot = np.transpose(np.squeeze(spec_batch[n].numpy(), 2))
        plt.pcolormesh(frame_vector_time, frequency_vector,spec_plot,cmap=cmap)
        plt.title(title)

    # save the image
    save_name = os.path.join(params.checkpoint_dir, params.start_date + '_' + params.end_date + '_' + params.data_type + '_spectrograms.png')
    plt.savefig(save_name, dpi=300)
    plt.close()


def accuracy_plots(args):
    path = args.checkpoint_dir
    log =  os.path.join(path,'log.csv')
    #%%
    df = pd.read_csv(log, delimiter=';')
    save = path  + 'loss.png'
    plt.plot(df['epoch'], df['loss'], 'b', linewidth= 2, label = "Training Loss")
    plt.plot(df['epoch'], df['val_loss'], 'r', linewidth= 2, label = "Validation Loss")
    plt.xlabel("epoch")
    plt.ylabel("loss")
    plt.grid()
    plt.legend()
    plt.savefig(save, bbox_inches='tight', dpi=300)
    plt.show()

    # %%

    # %%
    save  = path +'accuracy.png'
    plt.plot(df['epoch'], df['accuracy'], 'g', linewidth= 2, label = "Training Accuracy")
    plt.plot(df['epoch'], df['val_accuracy'], 'purple', linewidth= 2, label = "Validation Accuracy")
    plt.xlabel("epoch")
    plt.ylabel("loss / accuracy")
    plt.grid()
    plt.legend()
    plt.savefig(save, bbox_inches='tight', dpi=300)
    plt.show()

def audio_signal(args):
    t1 = main_pipeline.date_to_utc(args.start_date, 'second')
    t2 = main_pipeline.date_to_utc(args.end_date, 'second')
    dur = abs(t2-t1)
    wc = WavCrawler(args.database, t1, t2, segment_length=dur, overlap=0.25)
    segment = next(wc)
    if args.spectrogram_type=='raw':
        dataset, timestamps = wavcrawler_data_process(segment=segment, mode='single', channels=args.channels, segment_dur=dur, calibrate=False, sample_rate=args.sample_rate)
    elif args.spectrogram_type=='calibrated':
        dataset, timestamps = wavcrawler_data_process(segment=segment, mode='single', channels=args.channels, segment_dur=dur, calibrate=True, sample_rate=args.sample_rate)

    dataset = tf.reshape(tf.squeeze(dataset), [1,-1])
    dataset = dataset.numpy()[0]

def spectrogram_plot(args):

    print("making spectrogram")
    t1 = main_pipeline.date_to_utc(args.start_date, 'second')
    t2 = main_pipeline.date_to_utc(args.end_date, 'second')
    t1 = 1550880000
    t2 = 1550883600
    dur = 30
    wc = WavCrawler(args.database, t1, t2, segment_length=dur*8000, overlap=0.25)
    segment = next(wc)
    print("data obtained")

    '''
    if args.spectrogram_type=='andrew-raw' or args.spectrogram_type=='andrew-mel':
        filepath = '/smallwork/beards/CS4321/AVBW_Team/cs4321-team-sonar-final-project/data_test/audio/classB-_190809_09_2100.wav'


        WIN_SIZE = (int)((250 * .001) * 4000 )
        OVERLAP = 75
        # converts a overlap percent into number of sample points
        STEP = (int)((75 /100) * WIN_SIZE)
        SAMPLE_POINTS = 1024
        # mel bins is only used in MFCCs
        MEL_BINS = 128
        # MFCC Parameters
        # lower bound frequency in hz, selected to not include lower frequency DC signal
        LOWER_BOUND = 10.0
        # upper bound frequency in hz, selected to be max possible frequency
        UPPER_BOUND = 2000.0

        STEP = (int)((OVERLAP /100) * WIN_SIZE)

        LOWER_BOUND = 10.0
        # upper bound frequency in hz, selected to be max possible frequency
        UPPER_BOUND = 2000.0
        # Warp the linear scale spectrograms into the mel-scale.
        num_spectrogram_bins = (args.sample_pts //2) +1

        audio_data = tf.io.read_file(filepath)

        audio, _ = tf.audio.decode_wav(audio_data, desired_channels=4)

        dataset = audio[:,0]

        print("Dataset")
        print(dataset)

        channels = tf.split(audio, num_or_size_splits=4, axis=1) 
        
        all_channels = []

        for ch in channels:
            audio_squeeze = tf.reshape(tf.squeeze(ch), [1,-1])
            stfts = tf.signal.stft(audio_squeeze, frame_length=args.win_size, frame_step=STEP, fft_length=args.sample_pts, window_fn=tf.signal.hann_window, pad_end=True )
            spectrograms = tf.abs(stfts)

            linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(args.mel_bins, num_spectrogram_bins, args.sample_rate, LOWER_BOUND, UPPER_BOUND)
            mel_spectrograms = tf.tensordot( spectrograms, linear_to_mel_weight_matrix, 1)

            # Compute a stabilized log to get log-magnitude mel-scale spectrograms.
            log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)
            all_channels.append(tf.squeeze(log_mel_spectrograms))
        # mfcc function returns channels, time, freq, need to convert to time, freq, channels for CNNs
        dataset =  tf.stack([all_channels[0], all_channels[1], all_channels[2], all_channels[3]], axis=2)
    '''

    if args.data_type=='raw':

        dataset, times = wavcrawler_data_process(segment, 'single', 4, dur, False, args.sample_rate)
        dataset = dataset[:,0]

        '''
        dataset = data[:,0]

        print("Dataset")
        print(dataset)

        mel_data = generate_multi_channel_mfcc(data, 'single', 'wc', args.sample_rate)
        
        print("Mel data")
        print(mel_data)
        
        # This works
        #dataset=segment.samples[0, :]

        # Test
        target_num_samples = 30 * 4000

        #downsample_1 = scipy_signal.resample(segment[0][0], target_num_samples)
        #audio_1 = tf.convert_to_tensor([downsample_1], np.float32)
        #audio_1 = tf.reshape(audio_1, [target_num_samples,1])


        temp_data = []
        for i in range(0,4):
            data = scipy_signal.resample(segment[0][i], target_num_samples)
            temp_data.append(data)

        downsample_4 = np.array(temp_data)

        pre_audio_4 = tf.convert_to_tensor(downsample_4, np.float32)
        #audio_4 = tf.reshape(pre_audio_4, [target_num_samples, 4])
        audio_4 = tf.transpose(pre_audio_4)

        channels = tf.split(audio_4, num_or_size_splits=4, axis=1) 

        print("Downsampled raw audio")
        print(downsample_4)
        print(type(downsample_4))
        print(downsample_4.shape)

        print("Audio before reshape")
        print(pre_audio_4)
        print(type(pre_audio_4))
        print(pre_audio_4.shape)

        print("Audio")
        print(audio_4)
        print(type(audio_4))
        print(audio_4.shape)

        print("Channels")
        print(channels)
        print(type(channels))
        print(len(channels))

        dataset = channels[0][:,0]
        print("Dataset")
        print(dataset)

        dataset = generate_multi_channel_mfcc(audio_4, 'single', 'wc', args.sample_rate)

        print("Final Mel Spectrogram")
        print(dataset)
        print(dataset.shape)

        dataset = dataset[0]
        '''
        #dataset = audio_4[:,0]


        #f, t, Sxx = spectrogram(dataset, 8000)


    elif args.data_type=='calibrated':
        #dataset, timestamps = wavcrawler_data_process(segment=segment, mode='single', channels=args.channels, segment_dur=dur, calibrate=True, sample_rate=args.sample_rate)
        dataset = wavcrawler_calibration_filter(segment)
        dataset = dataset[0]
        
    elif args.data_type=='mel':
        dataset, timestamps = full_mel_mfcc_pipeline(segment, channels=args.channels, mode='single', source='wc', segment_dur=dur, calibrate=False, sample_rate=args.sample_rate)


    elif args.data_type=='calibrated-mel':
        dataset, timestamps = full_mel_mfcc_pipeline(segment, channels=args.channels, mode='single', source='wc', segment_dur=dur, calibrate=True, sample_rate=args.sample_rate)


    # This works!
    #cmap = plt.cm.get_cmap("jet")
    #plt.pcolormesh(t, f, Sxx,cmap=cmap)
    save_name = os.path.join(args.checkpoint_dir, args.start_date + '_' + args.end_date + '_' + args.data_type + '_spectrogram.png')

    if args.data_type=='calibrated' or args.data_type=='raw':
        fig, ax = plt.subplots(1, figsize=(10,10))
        Pxx, freqs, bins, im = ax.specgram(dataset, NFFT=args.sample_pts, Fs = 8000, noverlap=args.overlap)

        plt.xlabel("Time (sec)")
        plt.ylabel("Frequency (Hz)")
        #plt.title(args.start_date + ' to ' + args.end_date + ' Spectrogram')
        #plt.colorbar(format='%+2.0f dB')
        plt.savefig(save_name, dpi=300)
        plt.close()

    elif args.data_type=='calibrated-mel' or args.data_type=='mel':
        dataset = [dataset]

        step = (args.overlap/100 )* ((args.win_size * 0.001) * args.sample_rate)
        time_axis = (int)((args.duration * args.sample_rate) // step)
        # stft frequency axis is different than MFCC, time axises are the same
        if args.model_input == 'stft':
            freq_axis = (args.sample_pts//2) +1
        else:
            freq_axis = args.mel_bins

        #for spec_batch in dataset.take(1):
        generate_from_model(args, dataset, time_axis, freq_axis)

        # save the image
        plt.savefig(save_name, dpi=300)
        plt.close()
    

def ais_graph(args, start_date, end_date, ais_df, preds=pd.DataFrame()):
    orders_magnitude = 1000

    sensor_latitude = 36.712465
    sensor_longitude = -122.187548
    center_latitude=  36.712465
    center_longitude= -122.187548

    x_low = center_longitude + 1
    y_low = center_latitude - .75
    x_high = center_longitude - 1
    y_high = center_latitude + .75

    fig = plt.figure(figsize=(12,9))

    m = Basemap(projection='mill',
            llcrnrlat = y_low,
            urcrnrlat = y_high,
            llcrnrlon = x_high,
            urcrnrlon = x_low,
            resolution = 'h'
            )

    m.drawcoastlines()

    m.drawparallels(np.arange(y_low,y_high,.2), labels=[True,False,False,False])
    m.drawmeridians(np.arange(x_high,x_low,.2), labels=[0,0,0,1])

    #m.etopo()

    # Plot the track for each ship

    ship_handles_list = []
    for key, data in ais_df:
        sites_lat_y = data.lat.to_list()
        sites_lon_x = data.long.to_list()
        track = m.plot(sites_lon_x, sites_lat_y, latlon=True, color='gray', label="Ship Track")
        ship_handles_list.append(track[0])

    #leg0 = plt.legend(handles=ship_handles_list, loc='lower left', bbox_to_anchor=(.13, .06))
    leg0 = plt.legend(handles=track, loc='lower left', bbox_to_anchor=(.13, .06))
    plt.gca().add_artist(leg0)


    if not preds.empty:

        # Iterate through the prediction dataframe
        # grab the prediction times
        results_x = []
        results_y = []
        colors = []
        colors_for_map = {'Class A':'red', 'Class B':'green', 'Class C':'blue', 'Class D':'purple', 'Class E':'gray'}

        preds['start_time'] = preds['start_time'].apply(lambda x: utc_to_date(x))
        preds['end_time'] = preds['end_time'].apply(lambda x: utc_to_date(x))

        # Create legend for predicted ship classes
        m.plot([],[], marker="o", ms=10, ls="")

        texts = ["Class A", "Class B", "Class C", "Class D", "Class E"]
        #patches = [ m.plot([],[], marker="o", ms=10, ls="", mec=None, color=colors_for_map[i], 
        #            label="{:s}".format(texts[i]) )[0]  for i in range(len(texts)) ]
        patches = [ m.plot([],[], marker="o", ms=10, ls="", mec=None, color=colors_for_map[texts[i]], 
                    label="{:s}".format(texts[i]) )[0]  for i in range(len(texts)) ]

        leg1 = plt.legend(handles=patches, loc='lower left', title = "Predictions")
        plt.gca().add_artist(leg1)

        # Iterate through predictions, attach predictions to nearest ship position if it is correct
        
        for line in preds.iterrows():
            predict_class = line[1]['predict_labels']

            # Make list of the predicted classes in text format
            classes = ['Class A', 'Class B', 'Class C', 'Class D', 'Class E']
            present_classes = []
            for i in range(5):
                if predict_class[i]==1:
                    present_classes.append(classes[i])
            
            clip_time = line[1]['start_time']

            # put the prediction on the closest AIS time available.
            # Iterate through ais dataframe
            # If the prediction matches the class of the ship, then
            # check if the clip time is in the time that ship was active
            # If it was, then filter positions to only those within the predict time period
            # because we don't want 
            # attach the prediction to the closest ais time
            for key, value in ais_df:
                ship_class = value['class'].unique()[0]
                if ship_class in present_classes:
                    if value['time'].min()<=clip_time<=value['time'].max():
                        #tmp_value = value.set_index('time')
                        #tmp_value = tmp_value.between_time(start_date, end_date) #
                        tmp_value = value.loc[(start_date<=value['time']) & (value['time']<=end_date)]
                        print(tmp_value)
                        # If tmp value is empty, then there were no ais positions during the prediction time period, should not attach prediction to that ship
                        if not tmp_value.empty:
                            results_idx = tmp_value['time'].sub(clip_time).abs().idxmin() # results array is inference data and data is ais line plot
                            results_y.append(tmp_value['lat'][results_idx])
                            results_x.append(tmp_value['long'][results_idx])
                            colors.append(colors_for_map[ship_class])

                        '''
                        # new method
                        time_diffs = data['TIME'].sub(clip_time).abs()

                        #  we have the index of the smallest time difference, so now we will check to either side of that index
                        # The smaller one is the one the point lies between

                        timeplus = time_diffs[results_idx+1]
                        timeminus = time_diffs[results_idx-1]

                        smallest_time = min(timeplus, timeminus)

                        # Get the index of this time
                        results_idx_2 = time_diffs[time_diffs == smallest_time].index[0]

                        #results_idx_2 = data[data['TIME'] == smallest_time]['TIME'].index[0]

                        # Determine latitude/longitude difference between two times
                        closest_lat = data['LAT'][results_idx]
                        second_lat = data['LAT'][results_idx_2]

                        closest_long = data['LONG'][results_idx]
                        second_long = data['LONG'][results_idx_2]

                        closest_time = data['TIME'][results_idx]
                        second_time = data['TIME'][results_idx_2]

                        # Calculate the lat/long difference per second

                        seconds_diff = (closest_time - second_time).total_seconds()
                        lat_diff = abs(closest_lat - second_lat)
                        long_diff = abs(closest_long - second_long)

                        lat_per_sec = lat_diff/seconds_diff
                        long_per_sec = long_diff/seconds_diff

                        pred_seconds_diff = (clip_time - closest_time).total_seconds()

                        new_lat_diff = pred_seconds_diff * lat_per_sec
                        new_long_diff = pred_seconds_diff * long_per_sec

                        lat_diff_indicator = closest_lat < second_lat
                        long_diff_indicator = closest_long < second_long
                        # This means that we must subtract a range value from the closest range
                        if lat_diff_indicator:
                            new_lat = closest_lat - new_lat_diff
                        # Else we add to the range
                        else:
                            new_lat = closest_lat + new_lat_diff

                        results_y.append(new_lat)

                        # This means that we must subtract a range value from the closest range
                        if long_diff_indicator:
                            new_long = closest_long - new_long_diff
                        # Else we add to the range
                        else:
                            new_long = closest_long + new_long_diff

                        results_x.append(new_long)
                        '''
        if args.bnn:
            sizes = preds['entropy_vi'] * orders_magnitude

            sizes = sizes.to_numpy()

            percentile_25 = np.percentile(sizes, 25)
            percentile_50 = np.percentile(sizes, 50)
            percentile_75 = np.percentile(sizes, 75)

            scatter1 = plt.scatter([], [], c='k', alpha=0.3, s=percentile_25, label='25th Percentile' )
            scatter2 = plt.scatter([], [], c='k', alpha=0.3, s=percentile_50, label='50th Percentile')
            scatter3 = plt.scatter([], [], c='k', alpha=0.3, s=percentile_75, label='75th Percentile')

            m.scatter(results_x, results_y, latlon=True, alpha=.3, s=sizes.tolist(), c='gray', zorder=1)
            m.scatter(results_x, results_y, latlon=True, alpha=.6, s=50, c=colors, zorder=2)

            leg2 = plt.legend(handles = [scatter1, scatter2, scatter3], scatterpoints=1, frameon=True, labelspacing=2.5, handletextpad=2, loc='lower right', borderpad=2) #, bbox_to_anchor=(.35, 0)
            plt.gca().add_artist(leg2)
        else:
            m.scatter(results_x, results_y, latlon=True, s=50, c=colors, zorder=1)
            
    sensor = m.scatter([sensor_longitude], [sensor_latitude], c='black', alpha=1, s=100, marker='x', linewidth=3, label='Acoustic Sensor', latlon=True, zorder=3)
    leg3 = plt.legend(handles = [sensor], scatterpoints=1, frameon=True, labelspacing=1, loc='lower left', bbox_to_anchor=(.13, 0))

    # save plot
    save_name = os.path.join(args.checkpoint_dir, args.start_date + '_' + args.end_date + '_ais.png')
    plt.savefig(save_name, dpi=300)
    plt.close()

# Returns an ais dataframe from a tensorflow dataset
def format_ais(args, ais_dataset, batch_size, include_unknown=False, plot_range=30):
    try:
        start_date = datetime.datetime.strptime(args.start_date, '%Y%m%d %H%M%S')
        end_date = datetime.datetime.strptime(args.end_date, '%Y%m%d %H%M%S')
    except error as e:
        print(e)
        print("Please format the date correctly as YYYYMMDD HHMMSS")

    plot_data = []
    for item in ais_dataset.take(batch_size):
        tmp_plot_data = item[9].numpy()
        #length, width = tmp_plot_data.shape
        #new_length = length*width
        #tmp_plot_data = tmp_plot_data.reshape([new_length, height])
        for x in tmp_plot_data:
            plot_data.append(x)

        #plot_data = plot_data[9]
    ais_df = pd.DataFrame(plot_data, columns=['mmsi','time', 'lat', 'long','brg', 'rng','desig','class'])


    # Decode from bytes to normal strings
    ais_df = ais_df.stack().str.decode('utf-8').unstack()

    # There are filler positions with 0 to ensure that the data had the same shape, so we will drop these from the dataframe
    ais_df = ais_df[ais_df['time']!='0']

    # There are ships that had unknown designations, if you would like to plot these ships
    # then select include unknown
    if not include_unknown:
        ais_df = ais_df.dropna(subset=['class'])
        #ais_df = ais_df[ais_df['class'].notna()]


    # Convert columns to correct data types
    ais_df[["mmsi", "lat", "long", "brg", "rng"]] = ais_df[["mmsi", "lat", "long", "brg", "rng"]].apply(pd.to_numeric)

    ais_df['time'] = pd.to_datetime(ais_df['time'], format='%m/%d/%Y-%H:%M:%S')

    # There will be duplicates in the dataframe, so drop all duplicates
    ais_df = ais_df.drop_duplicates()

    
    # Need to figure out how to sort through ais positions
    #ais_df = ais_df[(ais_df['time']>=start_date) & (ais_df['time']<=end_date)]

    ais_df = ais_df.sort_values(by=['time'])

    # Group ais by mmsi
    ais_df_grouped = ais_df.groupby('mmsi')

    # Iterate through dataframe, if there is a ship that was active during the defined
    # Time period, save the ships mmsi and edit the dataframe
    # If the ship never got close to the sensor (within plot range), then discard it
    mmsi_list=[]
    for key, value in ais_df_grouped:
        start = value['time'].min()
        end = value['time'].max()
        min_range = value['rng'].min()
        if (start_date<=start<=end_date) or (start_date<=end<=end_date) or (start<=start_date and end>=end_date):
            if min_range<=(10):
                mmsi_list.append(key)

    new_ais_df = ais_df[ais_df.mmsi.isin(mmsi_list)]

    # Now filter the positions to only those within a particular range from the sensor
    new_ais_df = new_ais_df[new_ais_df['rng']<(plot_range+10)]

    new_ais_df = new_ais_df.groupby('mmsi')

    return new_ais_df


def ais_plot(args, preds=pd.DataFrame()):
    # Grab corresponding tfrecord names to defined times
    plot_files = []

    full_file_list = glob.glob(os.path.join(args.data_dir,"*.tfrecords"))
    file_list = []

    try:
        start_date = datetime.datetime.strptime(args.start_date, '%Y%m%d %H%M%S')
        end_date = datetime.datetime.strptime(args.end_date, '%Y%m%d %H%M%S')
    except error as e:
        print(e)
        print("Please format the date correctly as YYYYMMDD HHMMSS")

    # Don't want to run out of memory, so check the size of data
    time_diff = end_date - start_date
    if time_diff > datetime.timedelta(hours=1):
        print("The times you have entered spans a period greater than an hour, this may fill up available memory.")

    # Iterate through files, only keep the ones within the desired time period
    for fname in full_file_list:

        file_start_date, file_end_date = file_date(fname, 'second', 'both')

        '''
        element_list = re.split('_|\.',fname)
        file_end_date = datetime.datetime.strptime(element_list[-2], "%Y%m%d-%H%M%S")
        file_start_date = datetime.datetime.strptime(element_list[-3], "%Y%m%d-%H%M%S")
        '''
        if (start_date < file_start_date and file_start_date<=end_date<=file_end_date) or (file_start_date<=start_date<=file_end_date and file_end_date<end_date) or (file_start_date<=start_date<=file_end_date and file_start_date<=end_date<=file_end_date) or (start_date<=file_start_date and file_end_date<=end_date):
            file_list.append(fname)
        else:
            continue

        '''
        if (start_date <= file_start_date <= end_date) or (start_date <= file_end_date  <= end_date) or (file_start_date >= start_date and file_end_date >= end_date):
            file_list.append(fname)
        else:
            continue
        '''

        '''
        if not (start_date <= file_start_date <= end_date) and not (start_date <= file_end_date <= end_date):
            continue
        '''
        
    # Sort files by datetime
    plot_files = sorted(file_list, key = file_date)

    if len(plot_files) == 0:
        print("There are no tfrecords for this defined time period")

    # Get the data and batch the files into a single amount by the number of examples
    pre_plot_data, plot_metadata = get_audio_dataset(args, plot_files, args.batch_size, args.data_type, 'metadata')
    acoustic_data, plot_metadata = get_audio_dataset(args, plot_files, args.batch_size, args.data_type, 'features-times')

    batch_size = int(plot_metadata['Examples Count'])

    new_ais_df = format_ais(args, pre_plot_data, batch_size)

    '''
    plot_data = []
    for item in pre_plot_data.take(batch_size):
        tmp_plot_data = item[9].numpy()
        #length, width = tmp_plot_data.shape
        #new_length = length*width
        #tmp_plot_data = tmp_plot_data.reshape([new_length, height])
        for x in tmp_plot_data:
            plot_data.append(x)  
    '''

    acoustic_data = acoustic_data.batch(batch_size,drop_remainder=True)

    # get the ais data
    '''
    for item in acoustic_data.take(1):
        acoustic_data = item[0].numpy()
        #labels = item[1].numpy()
        #start_times = item[7].numpy()
        #end_times = item[8].numpy()
        #plot_data = item[9].numpy()
    '''
    '''
    # Get the AIS positions in the plot data and format into dataframe
    #plot_data = plot_data[9]
    ais_df = pd.DataFrame(plot_data, columns=['mmsi','time', 'lat', 'long','brg', 'rng','desig','class'])


    # Decode from bytes to normal strings
    ais_df = ais_df.stack().str.decode('utf-8').unstack()

    # There are filler positions with 0 to ensure that the data had the same shape, so we will drop these from the dataframe
    ais_df = ais_df[ais_df['time']!='0']

    # Convert columns to correct data types
    ais_df[["mmsi", "lat", "long", "brg", "rng"]] = ais_df[["mmsi", "lat", "long", "brg", "rng"]].apply(pd.to_numeric)

    # There will be duplicates in the dataframe, so drop all duplicates
    ais_df = ais_df.drop_duplicates()

    # Filter ais positions for only those in the desired time range (may not need to do this, or may need to add buffers)
    ais_df['time'] = pd.to_datetime(ais_df['time'], format='%m/%d/%Y-%H:%M:%S')

    # Need to figure out how to sort through ais positions
    #ais_df = ais_df[(ais_df['time']>=start_date) & (ais_df['time']<=end_date)]

    ais_df = ais_df.sort_values(by=['time'])
    print(ais_df)

    # Group ais by mmsi
    ais_df_grouped = ais_df.groupby('mmsi')

    # Iterate through dataframe, if there is a ship that was active during the defined
    # Time period, save the ships mmsi and edit the dataframe?
    mmsi_list=[]
    for key, value in ais_df_grouped:
        start = value['time'].min()
        end = value['time'].max()
        if (start_date<=start<=end_date) or (start_date<=end<=end_date) or (start<=start_date and end>=end_date):
            mmsi_list.append(key)

    new_ais_df = ais_df[ais_df.mmsi.isin(mmsi_list)]

    new_ais_df = new_ais_df.groupby('mmsi')

    '''

    # plot ais data
    if not preds.empty:
        # This means that there are predictions that should be plotted with the ais data
        ais_graph(args, start_date, end_date, new_ais_df, preds)
    else:
        ais_graph(args, start_date, end_date, new_ais_df)

    # Sort spectrogram data by time
    #acoustic_data
    #start_times

    step = (args.overlap/100 )* ((args.win_size * 0.001) * args.sample_rate)
    time_axis = (int)((args.duration * args.sample_rate) // step)
    # stft frequency axis is different than MFCC, time axises are the same
    if args.model_input == 'stft':
        freq_axis = (args.sample_pts//2) +1
    else:
        freq_axis = args.mel_bins

    for spec_batch, label_batch, start_times, end_times in acoustic_data.take(1):
        generate_from_model(args, spec_batch, label_batch, start_times, end_times, time_axis, freq_axis)

def main(args):
    if args.plot_type == 'accuracy':
        accuracy_plots(args)
    elif args.plot_type == 'spectrogram':
        spectrogram_plot(args)
    elif args.plot_type == 'ais':
        ais_plot(args)
